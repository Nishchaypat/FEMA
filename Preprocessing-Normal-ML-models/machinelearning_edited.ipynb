{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./embedding_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.070204</td>\n",
       "      <td>-0.008770</td>\n",
       "      <td>0.043136</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>-0.003530</td>\n",
       "      <td>-0.043949</td>\n",
       "      <td>-0.063978</td>\n",
       "      <td>0.031023</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011748</td>\n",
       "      <td>-0.034075</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>-0.055517</td>\n",
       "      <td>0.056087</td>\n",
       "      <td>-0.082603</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093810</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>-0.025807</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>-0.091922</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.085928</td>\n",
       "      <td>0.053427</td>\n",
       "      <td>0.043115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.034779</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>-0.022890</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.091709</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024416</td>\n",
       "      <td>-0.027415</td>\n",
       "      <td>0.059185</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.077611</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.061974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>0.038542</td>\n",
       "      <td>-0.029417</td>\n",
       "      <td>-0.010289</td>\n",
       "      <td>0.099276</td>\n",
       "      <td>0.035280</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020275</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>-0.023467</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>-0.081863</td>\n",
       "      <td>-0.074574</td>\n",
       "      <td>-0.081447</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>0.090254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036021</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>-0.078853</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>-0.010789</td>\n",
       "      <td>-0.037461</td>\n",
       "      <td>0.050773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>0.060240</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>-0.007279</td>\n",
       "      <td>-0.071487</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>-0.073475</td>\n",
       "      <td>-0.019975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>-0.127378</td>\n",
       "      <td>-0.035622</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.032791</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>-0.101238</td>\n",
       "      <td>0.050642</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>-0.036108</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>-0.099580</td>\n",
       "      <td>-0.047226</td>\n",
       "      <td>0.048763</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>-0.033347</td>\n",
       "      <td>-0.003136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>-0.023827</td>\n",
       "      <td>-0.038613</td>\n",
       "      <td>-0.159647</td>\n",
       "      <td>0.091117</td>\n",
       "      <td>0.090677</td>\n",
       "      <td>0.064806</td>\n",
       "      <td>0.044424</td>\n",
       "      <td>0.024652</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>-0.013500</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>0.046552</td>\n",
       "      <td>-0.018731</td>\n",
       "      <td>-0.050020</td>\n",
       "      <td>-0.063545</td>\n",
       "      <td>0.104332</td>\n",
       "      <td>-0.063869</td>\n",
       "      <td>-0.003804</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.065254</td>\n",
       "      <td>-0.029268</td>\n",
       "      <td>-0.025140</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>-0.054026</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.021785</td>\n",
       "      <td>0.089948</td>\n",
       "      <td>-0.022374</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>-0.036852</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.030158</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.088840</td>\n",
       "      <td>-0.017889</td>\n",
       "      <td>-0.034807</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>-0.015030</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>-0.054174</td>\n",
       "      <td>0.089745</td>\n",
       "      <td>0.069528</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>-0.000938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>-0.040112</td>\n",
       "      <td>-0.014209</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.104555</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>-0.076459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>-0.079557</td>\n",
       "      <td>-0.031732</td>\n",
       "      <td>0.043316</td>\n",
       "      <td>-0.041996</td>\n",
       "      <td>-0.021027</td>\n",
       "      <td>-0.034688</td>\n",
       "      <td>-0.095084</td>\n",
       "      <td>0.011953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15903</th>\n",
       "      <td>0.021867</td>\n",
       "      <td>-0.085692</td>\n",
       "      <td>-0.055113</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.023179</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>-0.061387</td>\n",
       "      <td>-0.029390</td>\n",
       "      <td>0.041821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.103484</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.105003</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.018871</td>\n",
       "      <td>0.032482</td>\n",
       "      <td>-0.050880</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15904 rows × 385 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.070204 -0.008770  0.043136  0.008349 -0.003530 -0.043949 -0.063978   \n",
       "1     -0.093810 -0.031431  0.006137 -0.025807  0.054908 -0.091922  0.013936   \n",
       "2     -0.024416 -0.027415  0.059185  0.030584  0.008155  0.023277  0.077611   \n",
       "3      0.020275  0.019129  0.148405 -0.023467  0.030795 -0.081863 -0.074574   \n",
       "4      0.071769  0.024622  0.060240 -0.003544 -0.007279 -0.071487  0.006605   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15899  0.036608  0.040078 -0.036108  0.074166 -0.099580 -0.047226  0.048763   \n",
       "15900 -0.013500 -0.021762  0.046552 -0.018731 -0.050020 -0.063545  0.104332   \n",
       "15901 -0.036852 -0.034307  0.050144 -0.001109 -0.030158  0.022011  0.088840   \n",
       "15902 -0.040112 -0.014209  0.053676  0.029903  0.104555  0.019520  0.017045   \n",
       "15903  0.021867 -0.085692 -0.055113 -0.002660  0.062058  0.023179  0.007122   \n",
       "\n",
       "              7         8         9  ...       375       376       377  \\\n",
       "0      0.031023 -0.033890  0.010571  ... -0.011748 -0.034075 -0.035429   \n",
       "1      0.085928  0.053427  0.043115  ...  0.004596  0.034779 -0.024485   \n",
       "2      0.003260  0.033820 -0.061974  ... -0.054259  0.029481  0.038542   \n",
       "3     -0.081447  0.024311  0.090254  ... -0.036021  0.037630 -0.078853   \n",
       "4      0.038584 -0.073475 -0.019975  ... -0.004719 -0.127378 -0.035622   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "15899  0.006629 -0.033347 -0.003136  ...  0.022644 -0.023827 -0.038613   \n",
       "15900 -0.063869 -0.003804  0.019809  ... -0.065254 -0.029268 -0.025140   \n",
       "15901 -0.017889 -0.034807 -0.035255  ...  0.015783 -0.015030  0.011388   \n",
       "15902  0.023559  0.019245 -0.076459  ... -0.039347 -0.079557 -0.031732   \n",
       "15903 -0.061387 -0.029390  0.041821  ...  0.054579 -0.000656  0.103484   \n",
       "\n",
       "            378       379       380       381       382       383  target  \n",
       "0      0.036711 -0.055517  0.056087 -0.082603  0.008035  0.012522       0  \n",
       "1     -0.022890  0.000626  0.108974  0.009772 -0.091709 -0.018188       0  \n",
       "2     -0.029417 -0.010289  0.099276  0.035280  0.000526  0.002207       0  \n",
       "3     -0.055925  0.000470  0.017865 -0.010789 -0.037461  0.050773       0  \n",
       "4     -0.001116  0.048698  0.032791  0.000421 -0.101238  0.050642       0  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "15899 -0.159647  0.091117  0.090677  0.064806  0.044424  0.024652       4  \n",
       "15900 -0.015719 -0.054026  0.068085  0.021785  0.089948 -0.022374       4  \n",
       "15901 -0.054174  0.089745  0.069528  0.002572 -0.057027 -0.000938       0  \n",
       "15902  0.043316 -0.041996 -0.021027 -0.034688 -0.095084  0.011953       0  \n",
       "15903  0.012666  0.105003  0.007646 -0.018871  0.032482 -0.050880       4  \n",
       "\n",
       "[15904 rows x 385 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "15899    4\n",
       "15900    4\n",
       "15901    0\n",
       "15902    0\n",
       "15903    4\n",
       "Name: target, Length: 15904, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = data.drop(columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.070204</td>\n",
       "      <td>-0.008770</td>\n",
       "      <td>0.043136</td>\n",
       "      <td>0.008349</td>\n",
       "      <td>-0.003530</td>\n",
       "      <td>-0.043949</td>\n",
       "      <td>-0.063978</td>\n",
       "      <td>0.031023</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>0.010571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>-0.011748</td>\n",
       "      <td>-0.034075</td>\n",
       "      <td>-0.035429</td>\n",
       "      <td>0.036711</td>\n",
       "      <td>-0.055517</td>\n",
       "      <td>0.056087</td>\n",
       "      <td>-0.082603</td>\n",
       "      <td>0.008035</td>\n",
       "      <td>0.012522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093810</td>\n",
       "      <td>-0.031431</td>\n",
       "      <td>0.006137</td>\n",
       "      <td>-0.025807</td>\n",
       "      <td>0.054908</td>\n",
       "      <td>-0.091922</td>\n",
       "      <td>0.013936</td>\n",
       "      <td>0.085928</td>\n",
       "      <td>0.053427</td>\n",
       "      <td>0.043115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090293</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.034779</td>\n",
       "      <td>-0.024485</td>\n",
       "      <td>-0.022890</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>0.009772</td>\n",
       "      <td>-0.091709</td>\n",
       "      <td>-0.018188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024416</td>\n",
       "      <td>-0.027415</td>\n",
       "      <td>0.059185</td>\n",
       "      <td>0.030584</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.077611</td>\n",
       "      <td>0.003260</td>\n",
       "      <td>0.033820</td>\n",
       "      <td>-0.061974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067273</td>\n",
       "      <td>-0.054259</td>\n",
       "      <td>0.029481</td>\n",
       "      <td>0.038542</td>\n",
       "      <td>-0.029417</td>\n",
       "      <td>-0.010289</td>\n",
       "      <td>0.099276</td>\n",
       "      <td>0.035280</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020275</td>\n",
       "      <td>0.019129</td>\n",
       "      <td>0.148405</td>\n",
       "      <td>-0.023467</td>\n",
       "      <td>0.030795</td>\n",
       "      <td>-0.081863</td>\n",
       "      <td>-0.074574</td>\n",
       "      <td>-0.081447</td>\n",
       "      <td>0.024311</td>\n",
       "      <td>0.090254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099079</td>\n",
       "      <td>-0.036021</td>\n",
       "      <td>0.037630</td>\n",
       "      <td>-0.078853</td>\n",
       "      <td>-0.055925</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.017865</td>\n",
       "      <td>-0.010789</td>\n",
       "      <td>-0.037461</td>\n",
       "      <td>0.050773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.071769</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>0.060240</td>\n",
       "      <td>-0.003544</td>\n",
       "      <td>-0.007279</td>\n",
       "      <td>-0.071487</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>-0.073475</td>\n",
       "      <td>-0.019975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103115</td>\n",
       "      <td>-0.004719</td>\n",
       "      <td>-0.127378</td>\n",
       "      <td>-0.035622</td>\n",
       "      <td>-0.001116</td>\n",
       "      <td>0.048698</td>\n",
       "      <td>0.032791</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>-0.101238</td>\n",
       "      <td>0.050642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>0.036608</td>\n",
       "      <td>0.040078</td>\n",
       "      <td>-0.036108</td>\n",
       "      <td>0.074166</td>\n",
       "      <td>-0.099580</td>\n",
       "      <td>-0.047226</td>\n",
       "      <td>0.048763</td>\n",
       "      <td>0.006629</td>\n",
       "      <td>-0.033347</td>\n",
       "      <td>-0.003136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030625</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>-0.023827</td>\n",
       "      <td>-0.038613</td>\n",
       "      <td>-0.159647</td>\n",
       "      <td>0.091117</td>\n",
       "      <td>0.090677</td>\n",
       "      <td>0.064806</td>\n",
       "      <td>0.044424</td>\n",
       "      <td>0.024652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>-0.013500</td>\n",
       "      <td>-0.021762</td>\n",
       "      <td>0.046552</td>\n",
       "      <td>-0.018731</td>\n",
       "      <td>-0.050020</td>\n",
       "      <td>-0.063545</td>\n",
       "      <td>0.104332</td>\n",
       "      <td>-0.063869</td>\n",
       "      <td>-0.003804</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006048</td>\n",
       "      <td>-0.065254</td>\n",
       "      <td>-0.029268</td>\n",
       "      <td>-0.025140</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>-0.054026</td>\n",
       "      <td>0.068085</td>\n",
       "      <td>0.021785</td>\n",
       "      <td>0.089948</td>\n",
       "      <td>-0.022374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>-0.036852</td>\n",
       "      <td>-0.034307</td>\n",
       "      <td>0.050144</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.030158</td>\n",
       "      <td>0.022011</td>\n",
       "      <td>0.088840</td>\n",
       "      <td>-0.017889</td>\n",
       "      <td>-0.034807</td>\n",
       "      <td>-0.035255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051233</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>-0.015030</td>\n",
       "      <td>0.011388</td>\n",
       "      <td>-0.054174</td>\n",
       "      <td>0.089745</td>\n",
       "      <td>0.069528</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>-0.057027</td>\n",
       "      <td>-0.000938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>-0.040112</td>\n",
       "      <td>-0.014209</td>\n",
       "      <td>0.053676</td>\n",
       "      <td>0.029903</td>\n",
       "      <td>0.104555</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.017045</td>\n",
       "      <td>0.023559</td>\n",
       "      <td>0.019245</td>\n",
       "      <td>-0.076459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002295</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>-0.079557</td>\n",
       "      <td>-0.031732</td>\n",
       "      <td>0.043316</td>\n",
       "      <td>-0.041996</td>\n",
       "      <td>-0.021027</td>\n",
       "      <td>-0.034688</td>\n",
       "      <td>-0.095084</td>\n",
       "      <td>0.011953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15903</th>\n",
       "      <td>0.021867</td>\n",
       "      <td>-0.085692</td>\n",
       "      <td>-0.055113</td>\n",
       "      <td>-0.002660</td>\n",
       "      <td>0.062058</td>\n",
       "      <td>0.023179</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>-0.061387</td>\n",
       "      <td>-0.029390</td>\n",
       "      <td>0.041821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094361</td>\n",
       "      <td>0.054579</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>0.103484</td>\n",
       "      <td>0.012666</td>\n",
       "      <td>0.105003</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>-0.018871</td>\n",
       "      <td>0.032482</td>\n",
       "      <td>-0.050880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15904 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0     -0.070204 -0.008770  0.043136  0.008349 -0.003530 -0.043949 -0.063978   \n",
       "1     -0.093810 -0.031431  0.006137 -0.025807  0.054908 -0.091922  0.013936   \n",
       "2     -0.024416 -0.027415  0.059185  0.030584  0.008155  0.023277  0.077611   \n",
       "3      0.020275  0.019129  0.148405 -0.023467  0.030795 -0.081863 -0.074574   \n",
       "4      0.071769  0.024622  0.060240 -0.003544 -0.007279 -0.071487  0.006605   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15899  0.036608  0.040078 -0.036108  0.074166 -0.099580 -0.047226  0.048763   \n",
       "15900 -0.013500 -0.021762  0.046552 -0.018731 -0.050020 -0.063545  0.104332   \n",
       "15901 -0.036852 -0.034307  0.050144 -0.001109 -0.030158  0.022011  0.088840   \n",
       "15902 -0.040112 -0.014209  0.053676  0.029903  0.104555  0.019520  0.017045   \n",
       "15903  0.021867 -0.085692 -0.055113 -0.002660  0.062058  0.023179  0.007122   \n",
       "\n",
       "              7         8         9  ...       374       375       376  \\\n",
       "0      0.031023 -0.033890  0.010571  ...  0.043862 -0.011748 -0.034075   \n",
       "1      0.085928  0.053427  0.043115  ...  0.090293  0.004596  0.034779   \n",
       "2      0.003260  0.033820 -0.061974  ...  0.067273 -0.054259  0.029481   \n",
       "3     -0.081447  0.024311  0.090254  ...  0.099079 -0.036021  0.037630   \n",
       "4      0.038584 -0.073475 -0.019975  ... -0.103115 -0.004719 -0.127378   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "15899  0.006629 -0.033347 -0.003136  ...  0.030625  0.022644 -0.023827   \n",
       "15900 -0.063869 -0.003804  0.019809  ...  0.006048 -0.065254 -0.029268   \n",
       "15901 -0.017889 -0.034807 -0.035255  ...  0.051233  0.015783 -0.015030   \n",
       "15902  0.023559  0.019245 -0.076459  ... -0.002295 -0.039347 -0.079557   \n",
       "15903 -0.061387 -0.029390  0.041821  ...  0.094361  0.054579 -0.000656   \n",
       "\n",
       "            377       378       379       380       381       382       383  \n",
       "0     -0.035429  0.036711 -0.055517  0.056087 -0.082603  0.008035  0.012522  \n",
       "1     -0.024485 -0.022890  0.000626  0.108974  0.009772 -0.091709 -0.018188  \n",
       "2      0.038542 -0.029417 -0.010289  0.099276  0.035280  0.000526  0.002207  \n",
       "3     -0.078853 -0.055925  0.000470  0.017865 -0.010789 -0.037461  0.050773  \n",
       "4     -0.035622 -0.001116  0.048698  0.032791  0.000421 -0.101238  0.050642  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "15899 -0.038613 -0.159647  0.091117  0.090677  0.064806  0.044424  0.024652  \n",
       "15900 -0.025140 -0.015719 -0.054026  0.068085  0.021785  0.089948 -0.022374  \n",
       "15901  0.011388 -0.054174  0.089745  0.069528  0.002572 -0.057027 -0.000938  \n",
       "15902 -0.031732  0.043316 -0.041996 -0.021027 -0.034688 -0.095084  0.011953  \n",
       "15903  0.103484  0.012666  0.105003  0.007646 -0.018871  0.032482 -0.050880  \n",
       "\n",
       "[15904 rows x 384 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15904,)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12723 samples\n",
      "Test set size: 3181 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'embeds' is your embeddings DataFrame (1590736 rows × 384 columns)\n",
    "# and 'target' is the target column (1590736 rows)\n",
    "\n",
    "# Combine embeddings and target into a single DataFrame for easy splitting\n",
    "\n",
    "# Define the features (X) and labels (y)\n",
    "X = data.iloc[:, :-1]  # All columns except the last one (features)\n",
    "y = data.iloc[:, -1]   # The last column (target)\n",
    "\n",
    "# Perform train-test split with stratification to maintain label balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Display the sizes of the splits to verify\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1588\n",
      "           4       0.73      0.75      0.74      1593\n",
      "\n",
      "    accuracy                           0.74      3181\n",
      "   macro avg       0.74      0.74      0.74      3181\n",
      "weighted avg       0.74      0.74      0.74      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "lr = LogisticRegression(max_iter=1000)  # Increase max_iter if needed\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = lr.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "60 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.72702997 0.72679409\n",
      " 0.7264011  0.7264011         nan        nan        nan        nan\n",
      " 0.73834733 0.73842585 0.73819003 0.73819003        nan        nan\n",
      "        nan        nan 0.73976199 0.73944771 0.73984094 0.73984094]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 1, 'penalty': 'l2', 'solver': 'sag'}\n",
      "Best cross-validation score: 0.7398409447554088\n"
     ]
    }
   ],
   "source": [
    "lr_param_grid = {\n",
    "    'C': [0.01, 0.1, 1],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'penalty' : ['none', 'l2']\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "grid_search = GridSearchCV(lr, lr_param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1588\n",
      "           4       0.73      0.75      0.74      1593\n",
      "\n",
      "    accuracy                           0.74      3181\n",
      "   macro avg       0.74      0.74      0.74      3181\n",
      "weighted avg       0.74      0.74      0.74      3181\n",
      "\n",
      "Accuracy Score: 0.7365608299276957\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, **grid_search.best_params_)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Re-evaluate\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7212\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.70      0.72      1588\n",
      "           4       0.71      0.74      0.73      1593\n",
      "\n",
      "    accuracy                           0.72      3181\n",
      "   macro avg       0.72      0.72      0.72      3181\n",
      "weighted avg       0.72      0.72      0.72      3181\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Assuming you already have X_train, X_test, y_train, y_test from your previous split\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the model on the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'var_smoothing': 0.3359818286283782}\n",
      "Best cross-validation score: 0.722314409805884\n"
     ]
    }
   ],
   "source": [
    "gnb_param_grid = {\n",
    "    'var_smoothing' : np.logspace(0,-9, num=20),\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gnb = GaussianNB()\n",
    "grid_search = GridSearchCV(gnb, gnb_param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.69      0.71      1588\n",
      "           4       0.71      0.74      0.72      1593\n",
      "\n",
      "    accuracy                           0.72      3181\n",
      "   macro avg       0.72      0.72      0.72      3181\n",
      "weighted avg       0.72      0.72      0.72      3181\n",
      "\n",
      "Accuracy Score: 0.7176988368437598\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(**grid_search.best_params_)\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Re-evaluate\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      1588\n",
      "           4       0.73      0.77      0.75      1593\n",
      "\n",
      "    accuracy                           0.75      3181\n",
      "   macro avg       0.75      0.75      0.74      3181\n",
      "weighted avg       0.75      0.75      0.74      3181\n",
      "\n",
      "Accuracy Score: 0.7450487268154669\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 20, 'gamma': 0.1}\n",
      "Best cross-validation score: 0.7448705687561008\n"
     ]
    }
   ],
   "source": [
    "svc_param_grid = {\n",
    "    'C': [0.01, 1, 10, 20],\n",
    "    \"gamma\": [0.01, 0.1]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "svc_model = SVC()\n",
    "grid_search = GridSearchCV(svc_model, svc_param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "\n",
    "# Best hyperparameters: {'C': 20, 'gamma': 0.01}\n",
    "# Best cross-validation score: 0.7310000000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.72      0.74      1588\n",
      "           4       0.73      0.77      0.75      1593\n",
      "\n",
      "    accuracy                           0.74      3181\n",
      "   macro avg       0.75      0.74      0.74      3181\n",
      "weighted avg       0.75      0.74      0.74      3181\n",
      "\n",
      "Accuracy Score: 0.7447343602640679\n"
     ]
    }
   ],
   "source": [
    "svc_model = SVC(**grid_search.best_params_)\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Re-evaluate\n",
    "y_pred = svc_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n",
      "/Users/dejauhnaebeadle/School/CSC4790-data-science/project/FEMA/.venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 1.0, 'fit_prior': True}\n",
      "Best cross-validation score: 0.7250416666666666\n"
     ]
    }
   ],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search = GridSearchCV(knn, knn_param_grid, cv=cv, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.74      0.74      3104\n",
      "           4       0.72      0.72      0.72      2896\n",
      "\n",
      "    accuracy                           0.73      6000\n",
      "   macro avg       0.73      0.73      0.73      6000\n",
      "weighted avg       0.73      0.73      0.73      6000\n",
      "\n",
      "Accuracy Score: 0.7326666666666667\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(**grid_search.best_params_)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Re-evaluate\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# # Initialize the SVM model with a linear kernel\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# svm.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# y_pred = svm.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# report = classification_report(y_test, y_pred)\n",
    "# print(f\"Accuracy: {accuracy:.4f}\")\n",
    "# print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(svm, 'svm_model.joblib')\n",
    "# print(\"Model saved as 'svm_model.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Adjust 'categorical_crossentropy' for multiclass\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n\u001b[0;32m     20\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Adjust input_shape as per features in X_train\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Use 'softmax' and adjust output layer if you have more than two classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Adjust 'categorical_crossentropy' for multiclass\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(\"int32\")  # Threshold for binary classification\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Classification Report:\\n{report}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
