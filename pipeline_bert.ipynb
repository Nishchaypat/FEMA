{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 18:24:18.599897: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom transformer for data preprocessing\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        df = pd.read_csv(X, encoding='utf-8', header=None, \n",
    "                        names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "        df.drop(columns=['ids', 'date', 'flag', 'user'], inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        return df\n",
    "\n",
    "# Custom transformer for BERT preprocessing\n",
    "class BertPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, preprocessor_url=\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"):\n",
    "        self.preprocessor_url = preprocessor_url\n",
    "        self.bert_preprocessor = hub.KerasLayer(preprocessor_url)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self.bert_preprocessor(X)\n",
    "\n",
    "# Custom estimator for BERT model\n",
    "class BertClassifier(BaseEstimator):\n",
    "    def __init__(self, bert_url=\"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\",\n",
    "                 batch_size=32, epochs=5):\n",
    "        self.bert_url = bert_url\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        bert_encoder = hub.KerasLayer(self.bert_url)\n",
    "        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "        preprocessed_text = BertPreprocessor()(text_input)\n",
    "        outputs = bert_encoder(preprocessed_text)\n",
    "        \n",
    "        net = outputs['pooled_output']\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(16, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "        \n",
    "        return tf.keras.Model(inputs=[text_input], outputs=[net])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model = self.build_model()\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        train_data = tf.data.Dataset.from_tensor_slices((X, y))\\\n",
    "            .batch(self.batch_size)\\\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        with tf.device('/GPU:0'):\n",
    "            self.model.fit(train_data, epochs=self.epochs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', DataPreprocessor()),\n",
    "    ('classifier', BertClassifier())\n",
    "])\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    data_file = 'data.csv'\n",
    "    processed_data = pipeline.named_steps['preprocessor'].fit_transform(data_file)\n",
    "    \n",
    "    # Prepare data for training\n",
    "    X = processed_data['text'].values\n",
    "    y = processed_data['target'].apply(lambda x: 0 if x == 0 else 1).values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    pipeline.named_steps['classifier'].fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    predictions = pipeline.named_steps['classifier'].predict(X_test)\n",
    "    accuracy = np.mean((predictions > 0.5) == y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
