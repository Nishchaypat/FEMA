{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Starting model training...\n",
      "Training the model...\n",
      "Epoch 1/5\n",
      "400/400 [==============================] - 58s 129ms/step - loss: 0.5247 - accuracy: 0.7641\n",
      "Epoch 2/5\n",
      "400/400 [==============================] - 51s 129ms/step - loss: 0.4859 - accuracy: 0.7816\n",
      "Epoch 3/5\n",
      "400/400 [==============================] - 51s 126ms/step - loss: 0.4658 - accuracy: 0.7941\n",
      "Epoch 4/5\n",
      "400/400 [==============================] - 51s 128ms/step - loss: 0.4654 - accuracy: 0.7984\n",
      "Epoch 5/5\n",
      "400/400 [==============================] - 53s 132ms/step - loss: 0.4654 - accuracy: 0.7891\n",
      "Making predictions...\n",
      "100/100 [==============================] - 13s 127ms/step\n",
      "Test Accuracy: 0.50\n",
      "Saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 360). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_sentiment_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline execution completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Data Preprocessor\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Read and preprocess the data\n",
    "        df = pd.read_csv(X, encoding='utf-8', header=None, \n",
    "                        names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "        df.drop(columns=['ids', 'date', 'flag', 'user'], inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        # Convert target to binary\n",
    "        df['target'] = df['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "        \n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "# BERT Model\n",
    "class BertModel(BaseEstimator):\n",
    "    def __init__(self, batch_size=32, epochs=5):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self.bert_url = \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\"\n",
    "        self.preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Create the BERT model\n",
    "        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "        preprocessor = hub.KerasLayer(self.preprocessor_url)\n",
    "        encoder = hub.KerasLayer(self.bert_url)\n",
    "        \n",
    "        # Preprocess text\n",
    "        preprocessed_text = preprocessor(text_input)\n",
    "        outputs = encoder(preprocessed_text)\n",
    "        \n",
    "        # Build the neural network\n",
    "        net = outputs['pooled_output']\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(16, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "        \n",
    "        return tf.keras.Model(text_input, net)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Build and compile the model\n",
    "        self.model = self.build_model()\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Prepare the dataset\n",
    "        train_data = tf.data.Dataset.from_tensor_slices((X, y))\\\n",
    "            .batch(self.batch_size)\\\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"Training the model...\")\n",
    "        with tf.device('/GPU:0' if len(tf.config.list_physical_devices('GPU')) > 0 else '/CPU:0'):\n",
    "            self.model.fit(train_data, epochs=self.epochs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        if self.model is not None:\n",
    "            self.model.save(path, include_optimizer=False)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            path, \n",
    "            custom_objects={'KerasLayer': hub.KerasLayer}\n",
    "        )\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = make_pipeline(\n",
    "    DataPreprocessor(),\n",
    "    BertModel(batch_size=32, epochs=5)\n",
    ")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    # Process the data\n",
    "    data_file = 'data.csv'  # Replace with your data file path\n",
    "    processed_data = pipeline.named_steps['datapreprocessor'].fit_transform(data_file)\n",
    "    \n",
    "    # Create smaller dataset for testing (1/100 of original size)\n",
    "    original_shape = processed_data.shape\n",
    "    new_size = original_shape[0] // 100\n",
    "    smaller_data = processed_data.sample(n=new_size, random_state=42)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = smaller_data['text'].values\n",
    "    y = smaller_data['target'].values\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting model training...\")\n",
    "    pipeline.named_steps['bertmodel'].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = pipeline.named_steps['bertmodel'].predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean((predictions > 0.5) == y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    print(\"Saving the model...\")\n",
    "    pipeline.named_steps['bertmodel'].save_model('bert_sentiment_model')\n",
    "    \n",
    "    print(\"Pipeline execution completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 104 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000209DBA83BE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 104 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000209DBA83BE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'This movie was fantastic!'\n",
      "Sentiment: positive\n",
      "\n",
      "Text: 'This movie was amazing!'\n",
      "Sentiment: positive\n",
      "\n",
      "Text: 'I really hated this film.'\n",
      "Sentiment: negative\n",
      "\n",
      "Text: 'The acting was pretty good.'\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "class FastBertPredictor:\n",
    "    def __init__(self, model_path='Best_82'):\n",
    "        # Load model once during initialization\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={'KerasLayer': hub.KerasLayer}\n",
    "        )\n",
    "        # Compile the model\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def predict(self, text):\n",
    "        # Convert input to array if it's a single string\n",
    "        if isinstance(text, str):\n",
    "            text = np.array([text])\n",
    "        elif isinstance(text, list):\n",
    "            text = np.array(text)\n",
    "            \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(text, verbose=0)  # Set verbose=0 to suppress output\n",
    "        return (prediction > 0.5).astype(int)\n",
    "\n",
    "# Initialize predictor once (globally)\n",
    "predictor = FastBertPredictor()\n",
    "\n",
    "def quick_predict(text):\n",
    "    \"\"\"\n",
    "    Fast prediction for a single text\n",
    "    \"\"\"\n",
    "    prediction = predictor.predict(text)\n",
    "    return \"positive\" if prediction[0] == 1 else \"negative\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Single text prediction\n",
    "    text = \"This movie was fantastic!\"\n",
    "    result = quick_predict(text)\n",
    "    print(f\"Text: '{text}'\\nSentiment: {result}\")\n",
    "    \n",
    "    # Multiple texts prediction (if needed)\n",
    "    texts = [\n",
    "        \"This movie was amazing!\",\n",
    "        \"I really hated this film.\",\n",
    "        \"The acting was pretty good.\"\n",
    "    ]\n",
    "    predictions = predictor.predict(texts)\n",
    "    for text, pred in zip(texts, predictions):\n",
    "        sentiment = \"positive\" if pred == 1 else \"negative\"\n",
    "        print(f\"\\nText: '{text}'\\nSentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 'I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming'\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Simple usage\n",
    "text = \"I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming\"\n",
    "result = quick_predict(text)\n",
    "print(f\"Text: '{text}'\\nSentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
