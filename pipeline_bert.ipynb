{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "class FastBertPredictor:\n",
    "    def __init__(self, model_path='Best_82'):\n",
    "        # Load model once during initialization\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={'KerasLayer': hub.KerasLayer}\n",
    "        )\n",
    "        # Compile the model\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "    def predict(self, text):\n",
    "        # Convert input to array if it's a single string\n",
    "        if isinstance(text, str):\n",
    "            text = np.array([text])\n",
    "        elif isinstance(text, list):\n",
    "            text = np.array(text)\n",
    "            \n",
    "        # Make prediction\n",
    "        prediction = self.model.predict(text, verbose=0)  # Set verbose=0 to suppress output\n",
    "        print(prediction)\n",
    "        return prediction\n",
    "\n",
    "# Initialize predictor once (globally)\n",
    "predictor = FastBertPredictor()\n",
    "\n",
    "def quick_predict(text):\n",
    "    \"\"\"\n",
    "    Fast prediction for a single text\n",
    "    \"\"\"\n",
    "    prediction = predictor.predict(text)\n",
    "    return \"positive\" if prediction[0] == 1 else \"negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67554706]]\n",
      "Text: 'I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming'\n",
      "Sentiment: negative\n",
      "[[0.67554706]]\n",
      "\n",
      "Text: 'I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming'\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Single text prediction\n",
    "    text = \"I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming\"\n",
    "    result = quick_predict(text)\n",
    "    print(f\"Text: '{text}'\\nSentiment: {result}\")\n",
    "    \n",
    "    # Multiple texts prediction (if needed)\n",
    "    texts = [\n",
    "        \"I am Nishchay, I love to play badminton, I hate the taste of bittergord, but I like swimming\"\n",
    "    ]\n",
    "    \n",
    "    predictions = predictor.predict(texts)\n",
    "    for text, pred in zip(texts, predictions):\n",
    "        sentiment = \"positive\" if pred == 1 else \"negative\"\n",
    "        print(f\"\\nText: '{text}'\\nSentiment: {sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_creds ={\n",
    "    \"apikey\": '_KnZKtXJvhFYIq2z5Ot08WKKpfBwbsgyj3CWsxYHJyds',\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: 'limit' is not provided. Only first 50 records will be displayed if the number of records exceed 50\n",
      "------------------------------------  ----------------------  ------------------------\n",
      "ID                                    NAME                    CREATED\n",
      "6760b3b6-140d-46c0-861e-2eebda2dd6ab  FEMA-SentimentAnalysis  2024-11-11T16:08:16.474Z\n",
      "------------------------------------  ----------------------  ------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>CREATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6760b3b6-140d-46c0-861e-2eebda2dd6ab</td>\n",
       "      <td>FEMA-SentimentAnalysis</td>\n",
       "      <td>2024-11-11T16:08:16.474Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID  ...                   CREATED\n",
       "0  6760b3b6-140d-46c0-861e-2eebda2dd6ab  ...  2024-11-11T16:08:16.474Z\n",
       "\n",
       "[1 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_client = APIClient(wml_credentials=wml_creds)\n",
    "wml_client.spaces.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID ='6760b3b6-140d-46c0-861e-2eebda2dd6ab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default space is set to: 6760b3b6-140d-46c0-861e-2eebda2dd6ab\n"
     ]
    }
   ],
   "source": [
    "wml_client.set.default_space(SPACE_ID)\n",
    "print(f\"Default space is set to: {SPACE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ibm_watson_machine_learning.wml_client_error:Saving trained model in repository failed. 'model_package/Best_82/saved_model.pb' file does not have valid format\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Saving trained model in repository failed. 'model_package/Best_82/saved_model.pb' file does not have valid format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 28\u001b[0m\n\u001b[1;32m     21\u001b[0m model_metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     22\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mModelMetaNames\u001b[38;5;241m.\u001b[39mNAME: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest_82\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mModelMetaNames\u001b[38;5;241m.\u001b[39mTYPE: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorflow_2.12\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mrepository\u001b[38;5;241m.\u001b[39mModelMetaNames\u001b[38;5;241m.\u001b[39mSOFTWARE_SPEC_UID: software_spec_uid\n\u001b[1;32m     25\u001b[0m }\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Store the model\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m model_uid \u001b[38;5;241m=\u001b[39m \u001b[43mwml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepository\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Print model UID\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel uploaded with UID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_uid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/repository.py:174\u001b[0m, in \u001b[0;36mRepository.store_model\u001b[0;34m(self, model, meta_props, training_data, training_target, pipeline, feature_names, label_column_names, subtrainingId, round_number, experiment_metadata, training_id)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@inherited_docstring\u001b[39m(Models\u001b[38;5;241m.\u001b[39mstore, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore()\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_model()\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstore_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, meta_props\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    172\u001b[0m                 feature_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, label_column_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,subtrainingId\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, round_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    173\u001b[0m                 experiment_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, training_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_props\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtraining_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_column_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43msubtrainingId\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubtrainingId\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mround_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mexperiment_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_metadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/models.py:1734\u001b[0m, in \u001b[0;36mModels.store\u001b[0;34m(self, model, meta_props, training_data, training_target, pipeline, version, artifactid, feature_names, label_column_names, subtrainingId, round_number, experiment_metadata, training_id)\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(model) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(model):\n\u001b[1;32m   1733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid path: neither file nor directory exists under this path: \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model))\n\u001b[0;32m-> 1734\u001b[0m     saved_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_props\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1735\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtraining_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43martifactid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifactid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mlabel_column_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_column_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1739\u001b[0m      saved_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_publish_from_training(model_uid\u001b[38;5;241m=\u001b[39mmodel, meta_props\u001b[38;5;241m=\u001b[39mmeta_props,\n\u001b[1;32m   1740\u001b[0m                                                subtrainingId\u001b[38;5;241m=\u001b[39msubtrainingId, feature_names\u001b[38;5;241m=\u001b[39mfeature_names,\n\u001b[1;32m   1741\u001b[0m                                                label_column_names\u001b[38;5;241m=\u001b[39mlabel_column_names, round_number\u001b[38;5;241m=\u001b[39mround_number)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/models.py:1066\u001b[0m, in \u001b[0;36mModels._publish_from_file\u001b[0;34m(self, model, meta_props, training_data, training_target, ver, artifactid, feature_names, label_column_names)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(output_filename)\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1066\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving trained model in repository failed. \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m file does not have valid format\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_filepath))\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Saving trained model in repository failed. 'model_package/Best_82/saved_model.pb' file does not have valid format"
     ]
    }
   ],
   "source": [
    "# Set Python Version and Runtime for TensorFlow\n",
    "software_spec_uid = wml_client.software_specifications.get_id_by_name('tensorflow_rt23.1-py3.10')\n",
    "\n",
    "# # Setup model meta for custom TensorFlow model\n",
    "# model_props = {\n",
    "#     wml_client.repository.ModelMetaNames.NAME: 'FastBert Model', \n",
    "#     wml_client.repository.ModelMetaNames.TYPE: 'tensorflow_2.12',\n",
    "#     wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "# }\n",
    "model_dir = 'model_package/Best_82/saved_model.pb'\n",
    "\n",
    "# Define the location of requirements.txt\n",
    "requirements_file = 'requirements.txt'\n",
    "\n",
    "# Define the location of pipeline.py\n",
    "pipeline_file = 'pipeline.py'\n",
    "\n",
    "# Create the client to interact with WML\n",
    "\n",
    "# Upload the model\n",
    "model_metadata = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: \"Best_82\",\n",
    "    wml_client.repository.ModelMetaNames.TYPE: \"tensorflow_2.12\",\n",
    "    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "# Store the model\n",
    "model_uid = wml_client.repository.store_model(model = model_dir, meta_props=model_metadata)\n",
    "\n",
    "# Print model UID\n",
    "print(f\"Model uploaded with UID: {model_uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '882a737a-a1a2-47a7-be8c-1113bdabc7ce' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "initializing\n",
      "Note: Software specifications Tensorflow 2.12 is deprecated. Use Tensorflow with a supported model type and software specification. For details, see https://dataplatform.cloud.ibm.com/docs/content/wsj/wmls/wmls-deploy-python-types.html?context=cpdaas.\n",
      "......."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deployment creation failed for deployment id: fb53b529-17ac-45e2-b65b-687bc6944e45. Errors: [{'code': 'f63377faa6becd4a47dcc7067ba1c40d', 'message': \"Tensorflow model load failed with error: Op type not registered 'CaseFoldUTF8' in binary running on wml-dep-od-tensorflow2.12-cl-yn19y5di-7f45c899bc-sx4cj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed..\"}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "failed\n",
      "\n",
      "--------------------------\n",
      "Deployment creation failed\n",
      "--------------------------\n",
      "\n",
      "\n",
      "Tensorflow model load failed with error: Op type not registered 'CaseFoldUTF8' in binary running on wml-dep-od-tensorflow2.12-cl-yn19y5di-7f45c899bc-sx4cj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed..\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Deployment creation failed for deployment id: fb53b529-17ac-45e2-b65b-687bc6944e45. Errors: [{'code': 'f63377faa6becd4a47dcc7067ba1c40d', 'message': \"Tensorflow model load failed with error: Op type not registered 'CaseFoldUTF8' in binary running on wml-dep-od-tensorflow2.12-cl-yn19y5di-7f45c899bc-sx4cj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed..\"}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 21\u001b[0m\n\u001b[1;32m      9\u001b[0m deployment_props \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     10\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mdeployments\u001b[38;5;241m.\u001b[39mConfigurationMetaNames\u001b[38;5;241m.\u001b[39mNAME: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEMA-SentimentAnalysis\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     wml_client\u001b[38;5;241m.\u001b[39mdeployments\u001b[38;5;241m.\u001b[39mConfigurationMetaNames\u001b[38;5;241m.\u001b[39mONLINE: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m }\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Deploy the model\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m deployment \u001b[38;5;241m=\u001b[39m \u001b[43mwml_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_uid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_uid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_props\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeployment_props\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Output result\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeployment created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeployment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/deployments.py:244\u001b[0m, in \u001b[0;36mDeployments.create\u001b[0;34m(self, artifact_uid, meta_props, rev_id, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m         print_text_header_h2(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeployment creation failed\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deployment_status_errors_handling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeployment_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeployment_uid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeployment creation failed\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/deployments.py:68\u001b[0m, in \u001b[0;36mDeployments._deployment_status_errors_handling\u001b[0;34m(self, deployment_details, operation_name, deployment_id)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeployment \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m operation_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed for deployment id: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m deployment_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Error: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(deployment_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeployment \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m operation_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/ibm_watson_machine_learning/deployments.py:63\u001b[0m, in \u001b[0;36mDeployments._deployment_status_errors_handling\u001b[0;34m(self, deployment_details, operation_name, deployment_id)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28mprint\u001b[39m(error)\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDeployment \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m operation_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed for deployment id: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m deployment_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Errors: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(errors))\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(deployment_details[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Deployment creation failed for deployment id: fb53b529-17ac-45e2-b65b-687bc6944e45. Errors: [{'code': 'f63377faa6becd4a47dcc7067ba1c40d', 'message': \"Tensorflow model load failed with error: Op type not registered 'CaseFoldUTF8' in binary running on wml-dep-od-tensorflow2.12-cl-yn19y5di-7f45c899bc-sx4cj. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed..\"}]"
     ]
    }
   ],
   "source": [
    "# model_details = wml_client.repository.store_model(\n",
    "#     model='model_package',  # Path to the zip file\n",
    "#     meta_props=model_props\n",
    "# )\n",
    "# model_details\n",
    "\n",
    "model_uid = model_uid['metadata']['id']\n",
    "\n",
    "deployment_props = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: 'FEMA-SentimentAnalysis',\n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {\n",
    "        \"dependencies\": {\n",
    "            \"pip_requirements\": requirements_file,  # Point to the requirements file\n",
    "            \"python\": \"3.10\"  # Ensure the Python version is appropriate\n",
    "        },\n",
    "        \"pipeline\": pipeline_file  # Ensure the pipeline file is used for inference\n",
    "    }\n",
    "}\n",
    "\n",
    "# Deploy the model\n",
    "deployment = wml_client.deployments.create(\n",
    "    artifact_uid=model_uid,\n",
    "    meta_props=deployment_props\n",
    ")\n",
    "\n",
    "# Output result\n",
    "print(f\"Deployment created: {deployment}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model UID: 43bbd541-907f-4594-b0ed-afff335f7a49\n"
     ]
    }
   ],
   "source": [
    "model_uid = wml_client.repository.get_model_id(model_details)\n",
    "print(f'Model UID: {model_uid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_props = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: 'FEMA-SentimentAnalysis', \n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "}\n",
    "\n",
    "# Deploy the model\n",
    "deployment = wml_client.deployments.create(\n",
    "    artifact_uid=model_uid, \n",
    "    meta_props=deployment_props\n",
    ")\n",
    "\n",
    "# Output result\n",
    "print(deployment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "software_specs = wml_client.software_specifications.list()\n",
    "for spec in software_specs['resources']:\n",
    "    print(spec['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Op type not registered 'CaseFoldUTF8' in binary running on HONC02FT05FML7M. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved in TensorFlow SavedModel format at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Initialize predictor and re-save the model\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mFastBertPredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBest_82\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m predictor\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest_82_saved\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[79], line 7\u001b[0m, in \u001b[0;36mFastBertPredictor.__init__\u001b[0;34m(self, model_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest_82\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the model with custom objects\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKerasLayer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhub\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKerasLayer\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/keras/src/saving/saving_api.py:238\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    231\u001b[0m         filepath,\n\u001b[1;32m    232\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    234\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/Text-Analysis/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3749\u001b[0m, in \u001b[0;36mGraph.op_def_for_type\u001b[0;34m(self, type)\u001b[0m\n\u001b[1;32m   3746\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n\u001b[1;32m   3747\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3748\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m] \u001b[38;5;241m=\u001b[39m op_def_pb2\u001b[38;5;241m.\u001b[39mOpDef\u001b[38;5;241m.\u001b[39mFromString(\n\u001b[0;32m-> 3749\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op_def_for_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3750\u001b[0m   )\n\u001b[1;32m   3751\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_op_def_cache[\u001b[38;5;28mtype\u001b[39m]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Op type not registered 'CaseFoldUTF8' in binary running on HONC02FT05FML7M. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "class FastBertPredictor:\n",
    "    def __init__(self, model_path='Best_82'):\n",
    "        # Load the model with custom objects\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            model_path,\n",
    "            custom_objects={'KerasLayer': hub.KerasLayer}\n",
    "        )\n",
    "\n",
    "    def save_model(self, save_path='Best_82_saved'):\n",
    "        # Re-save the model in TensorFlow's SavedModel format explicitly\n",
    "        tf.saved_model.save(self.model, save_path)\n",
    "        print(f\"Model saved in TensorFlow SavedModel format at {save_path}\")\n",
    "\n",
    "# Initialize predictor and re-save the model\n",
    "predictor = FastBertPredictor('Best_82')\n",
    "predictor.save_model('Best_82_saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
