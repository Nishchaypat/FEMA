{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv', encoding='utf-8', header=None, names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "data.drop(columns=['ids', 'date', 'flag', 'user'], inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data, random_state=42).reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "#from official.nlp import optimization  # to create AdamW optimizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'target' to bnary sentiment labels (0 or 1)\n",
    "df['target'] = df['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert data to TensorFlow datasets\n",
    "train_data = tf.data.Dataset.from_tensor_slices((train_df['text'].values, train_df['target'].values))\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_df['text'].values, test_df['target'].values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data_outliersremoved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_url = \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\"  # SST-2 model trained for sentiment analysis\n",
    "preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "\n",
    "bert_preprocessor = hub.KerasLayer(preprocessor_url)\n",
    "bert_encoder = hub.KerasLayer(bert_model_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessed_text = bert_preprocessor(text_input)\n",
    "    outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "    # Extract the pooled output from the BERT encoder\n",
    "    net = outputs['pooled_output']\n",
    "    \n",
    "    # Add dropout for regularization\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    \n",
    "    # Add additional dense layers with ReLU activation\n",
    "    net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)  # Add dropout to the new dense layer\n",
    "    net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    net = tf.keras.layers.Dense(16, activation='relu')(net)\n",
    "    net = tf.keras.layers.Dropout(0.2)(net)\n",
    "    \n",
    "    # Final output layer with sigmoid activation for binary classification\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    \n",
    "    return tf.keras.Model(inputs=[text_input], outputs=[net])\n",
    "\n",
    "# Initialize and build the model\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original shape\n",
    "original_shape = df.shape\n",
    "print(\"Original DataFrame shape:\", original_shape)\n",
    "\n",
    "# Calculate the new size (1/100 of the original)\n",
    "new_size = original_shape[0] // 100  # integer division to get the whole number\n",
    "print(\"New size for training data:\", new_size)\n",
    "\n",
    "# Randomly sample the training data\n",
    "smaller_train_df = train_df.sample(n=new_size, random_state=42)\n",
    "\n",
    "# Check the shape of the new training dataset\n",
    "print(\"Smaller Training DataFrame shape:\", smaller_train_df.shape)\n",
    "\n",
    "smaller_train_data = tf.data.Dataset.from_tensor_slices((smaller_train_df['text'].values, smaller_train_df['target'].values))\n",
    "\n",
    "smaller_test_df = test_df.sample(n=new_size, random_state=42)\n",
    "\n",
    "# Check the shape of the new training dataset\n",
    "print(\"Smaller Training DataFrame shape:\", smaller_test_df.shape)\n",
    "\n",
    "smaller_test_data = tf.data.Dataset.from_tensor_slices((smaller_test_df['text'].values, smaller_test_df['target'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_df['text'].values, train_df['target'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_data =smaller_train_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_data = smaller_test_data.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(train_data, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_data)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Test_79', include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('Test_79', custom_objects={'KerasLayer': hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "HYPERTUNNING\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras_tuner as kt\n",
    "\n",
    "# Hypermodel definition\n",
    "def build_hypermodel(hp):\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessed_text = bert_preprocessor(text_input)\n",
    "    outputs = bert_encoder(preprocessed_text)\n",
    "    \n",
    "    # BERT pooled output\n",
    "    net = outputs['pooled_output']\n",
    "    \n",
    "    # Add dense layers with hyperparameter tuning\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):  # Tune 1 to 3 additional layers\n",
    "        net = tf.keras.layers.Dense(\n",
    "            units=hp.Choice(f\"units_{i}\", [32, 64, 128]),  # Tune size per layer\n",
    "            activation='relu'\n",
    "        )(net)\n",
    "        net = tf.keras.layers.Dropout(hp.Float(f\"dropout_{i}\", 0.1, 0.5, step=0.1))(net)\n",
    "    \n",
    "    # Output layer\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    \n",
    "    # Compile the model\n",
    "    model = tf.keras.Model(inputs=[text_input], outputs=[net])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=hp.Choice(\"learning_rate\", [1e-5, 3e-5, 1e-4])\n",
    "        ),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Hyperparameter tuning setup\n",
    "tuner = kt.Hyperband(\n",
    "    build_hypermodel,\n",
    "    objective='accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperband_dir',\n",
    "    project_name='text_sentiment_analysis'\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "tuner.search(train_data, epochs=5)\n",
    "\n",
    "# Retrieve best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Summary of the best model\n",
    "best_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "BEST PARAMETERS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial Information\n",
    "\n",
    "## Trial ID\n",
    "- **ID:** 0020\n",
    "\n",
    "## Hyperparameters\n",
    "- **Hyperparameter Space:**\n",
    "  - `num_layers`: \n",
    "    - Type: Integer\n",
    "    - Range: [1, 3]\n",
    "  - `units_0`: \n",
    "    - Type: Choice\n",
    "    - Options: [32, 64, 128]\n",
    "    - Default: 32\n",
    "  - `dropout_0`: \n",
    "    - Type: Float\n",
    "    - Range: [0.1, 0.5]\n",
    "    - Default: 0.1\n",
    "  - `learning_rate`: \n",
    "    - Type: Choice\n",
    "    - Options: [1e-05, 3e-05, 0.0001]\n",
    "    - Default: 1e-05\n",
    "  - `units_1`: \n",
    "    - Type: Choice\n",
    "    - Options: [32, 64, 128]\n",
    "    - Default: 32\n",
    "  - `dropout_1`: \n",
    "    - Type: Float\n",
    "    - Range: [0.1, 0.5]\n",
    "    - Default: 0.1\n",
    "  - `units_2`: \n",
    "    - Type: Choice\n",
    "    - Options: [32, 64, 128]\n",
    "    - Default: 32\n",
    "  - `dropout_2`: \n",
    "    - Type: Float\n",
    "    - Range: [0.1, 0.5]\n",
    "    - Default: 0.1\n",
    "\n",
    "- **Selected Values:**\n",
    "  - `num_layers`: 1\n",
    "  - `units_0`: 128\n",
    "  - `dropout_0`: 0.2\n",
    "  - `learning_rate`: 0.0001\n",
    "  - `units_1`: 128\n",
    "  - `dropout_1`: 0.2\n",
    "  - `units_2`: 64\n",
    "  - `dropout_2`: 0.4\n",
    "\n",
    "## Tuner Information\n",
    "- **Epochs:** 10\n",
    "- **Initial Epoch:** 4\n",
    "- **Bracket:** 1\n",
    "- **Round:** 1\n",
    "- **Trial ID:** 0017\n",
    "\n",
    "## Metrics\n",
    "- **Loss:**\n",
    "  - Direction: Minimize\n",
    "  - Observations: \n",
    "    - Value: 0.3865 at Step 5\n",
    "- **Accuracy:**\n",
    "  - Direction: Maximize\n",
    "  - Observations: \n",
    "    - Value: 0.8277 at Step 5\n",
    "\n",
    "## Score\n",
    "- **Best Score:** 0.8277\n",
    "- **Best Step:** 5\n",
    "- **Status:** Completed\n",
    "- **Message:** None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
