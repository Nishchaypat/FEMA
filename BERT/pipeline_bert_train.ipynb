{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessor\n",
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Read and preprocess the data\n",
    "        df = pd.read_csv(X, encoding='utf-8', header=None, \n",
    "                        names=['target', 'ids', 'date', 'flag', 'user', 'text'])\n",
    "        df.drop(columns=['ids', 'date', 'flag', 'user'], inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        df = shuffle(df, random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        # Convert target to binary\n",
    "        df['target'] = df['target'].apply(lambda x: 0 if x == 0 else 1)\n",
    "        \n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "# BERT Model\n",
    "class BertModel(BaseEstimator):\n",
    "    def __init__(self, batch_size=32, epochs=5):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self.bert_url = \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\"\n",
    "        self.preprocessor_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Create the BERT model\n",
    "        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "        preprocessor = hub.KerasLayer(self.preprocessor_url)\n",
    "        encoder = hub.KerasLayer(self.bert_url)\n",
    "        \n",
    "        # Preprocess text\n",
    "        preprocessed_text = preprocessor(text_input)\n",
    "        outputs = encoder(preprocessed_text)\n",
    "        \n",
    "        # Build the neural network\n",
    "        net = outputs['pooled_output']\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(128, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(16, activation='relu')(net)\n",
    "        net = tf.keras.layers.Dropout(0.2)(net)\n",
    "        net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "        \n",
    "        return tf.keras.Model(text_input, net)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Build and compile the model\n",
    "        self.model = self.build_model()\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        # Prepare the dataset\n",
    "        train_data = tf.data.Dataset.from_tensor_slices((X, y))\\\n",
    "            .batch(self.batch_size)\\\n",
    "            .prefetch(tf.data.AUTOTUNE)\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"Training the model...\")\n",
    "        with tf.device('/GPU:0' if len(tf.config.list_physical_devices('GPU')) > 0 else '/CPU:0'):\n",
    "            self.model.fit(train_data, epochs=self.epochs)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model needs to be fitted before making predictions\")\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        if self.model is not None:\n",
    "            self.model.save(path, include_optimizer=False)\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            path, \n",
    "            custom_objects={'KerasLayer': hub.KerasLayer}\n",
    "        )\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = make_pipeline(\n",
    "    DataPreprocessor(),\n",
    "    BertModel(batch_size=32, epochs=5)\n",
    ")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(42)\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Check for GPU availability\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "    \n",
    "    # Process the data\n",
    "    data_file = 'data.csv'  # Replace with your data file path\n",
    "    processed_data = pipeline.named_steps['datapreprocessor'].fit_transform(data_file)\n",
    "    \n",
    "    # Create smaller dataset for testing (1/100 of original size)\n",
    "    original_shape = processed_data.shape\n",
    "    new_size = original_shape[0] // 100\n",
    "    smaller_data = processed_data.sample(n=new_size, random_state=42)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = smaller_data['text'].values\n",
    "    y = smaller_data['target'].values\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting model training...\")\n",
    "    pipeline.named_steps['bertmodel'].fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Making predictions...\")\n",
    "    predictions = pipeline.named_steps['bertmodel'].predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean((predictions > 0.5) == y_test)\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    print(\"Saving the model...\")\n",
    "    pipeline.named_steps['bertmodel'].save_model('bert_sentiment_model')\n",
    "    \n",
    "    print(\"Pipeline execution completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
