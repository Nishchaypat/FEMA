{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from numpy import array\n",
    "\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv1D, RNN, Embedding, SimpleRNN, Dense\n",
    "\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = shuffle(data, random_state=42).reset_index(drop=True)\n",
    "data['target'] = data['target'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text'].tolist()\n",
    "Y = data['target'].tolist()\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [str(text) for text in X_train if isinstance(text, (str, float))]\n",
    "X_test = [str(text) for text in X_test if isinstance(text, (str, float))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = word_tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('a2_glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embedding_matrix)\n",
    "np.savetxt('embedding_matrix_lstm.csv', embedding_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "SAVED\n",
    "_________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embedding_matrix = np.loadtxt('embedding_matrix_lstm.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "\n",
    "snn_model.add(embedding_layer)\n",
    "\n",
    "snn_model.add(Flatten())\n",
    "snn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(snn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model_history = snn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = snn_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(snn_model_history.history['acc'])\n",
    "plt.plot(snn_model_history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(snn_model_history.history['loss'])\n",
    "plt.plot(snn_model_history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen , trainable=False)\n",
    "cnn_model.add(embedding_layer)\n",
    "\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(cnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cnn_model_history.history['acc'])\n",
    "plt.plot(cnn_model_history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(cnn_model_history.history['loss'])\n",
    "plt.plot(cnn_model_history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "rnn_model.add(embedding_layer)\n",
    "\n",
    "rnn_model.add(SimpleRNN(128))\n",
    "\n",
    "rnn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "rnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model_history = rnn_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = rnn_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "\n",
    "# Embedding layer (use pre-trained embeddings like GloVe or FastText, fine-tune during training)\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "lstm_model.add(embedding_layer)\n",
    "\n",
    "# Bidirectional LSTM Layer (captures context from both ends of the sentence)\n",
    "lstm_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "\n",
    "# Attention Layer (self-attention)\n",
    "# Pass the same tensor as both query and value\n",
    "attention_output = Attention()([lstm_model.output, lstm_model.output])\n",
    "\n",
    "# Global Average Pooling to reduce the output dimensionality\n",
    "lstm_model.add(GlobalAveragePooling1D())\n",
    "\n",
    "# Dropout Layer (regularization to prevent overfitting)\n",
    "lstm_model.add(Dropout(0.5))\n",
    "\n",
    "# Dense Layer (final classification layer)\n",
    "lstm_model.add(Dense(64, activation='relu'))\n",
    "lstm_model.add(Dropout(0.5))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_history = lstm_model.fit(X_train, y_train, batch_size=128, epochs=6, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lstm_model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lstm_model_history.history['accuracy'])\n",
    "plt.plot(lstm_model_history.history['val_accuracy'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lstm_model_history.history['loss'])\n",
    "plt.plot(lstm_model_history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Attention, GlobalAveragePooling1D, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_model(hp):\n",
    "    # Define the model architecture\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    # Embedding layer (use pre-trained embeddings like GloVe or FastText, fine-tune during training)\n",
    "    embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=maxlen, trainable=False)\n",
    "    lstm_model.add(embedding_layer)\n",
    "\n",
    "    # Bidirectional LSTM Layer (captures context from both ends of the sentence)\n",
    "    lstm_model.add(Bidirectional(LSTM(\n",
    "        units=hp.Int('lstm_units', min_value=128, max_value=240, step=32), \n",
    "        return_sequences=True)))\n",
    "\n",
    "    # Attention Layer (self-attention)\n",
    "    attention_output = Attention()([lstm_model.output, lstm_model.output])\n",
    "\n",
    "    # Global Average Pooling to reduce the output dimensionality\n",
    "    lstm_model.add(GlobalAveragePooling1D())\n",
    "\n",
    "    # Dropout Layer (regularization to prevent overfitting)\n",
    "    lstm_model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "\n",
    "    # Dense Layer (final classification layer)\n",
    "    lstm_model.add(Dense(\n",
    "        units=hp.Int('dense_units', min_value=64, max_value=180, step=32),\n",
    "        activation='relu'))\n",
    "    lstm_model.add(Dropout(rate=hp.Float('dropout_rate_2', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "    lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with an optimizer\n",
    "    lstm_model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG')),\n",
    "        loss='binary_crossentropy',  # Use binary crossentropy for binary classification tasks\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return lstm_model\n",
    "\n",
    "# Define the tuner\n",
    "tuner = kt.BayesianOptimization(\n",
    "    build_model,\n",
    "    objective='accuracy',\n",
    "    max_trials=10,  # Number of trials to run\n",
    "    executions_per_trial=1,  # Run each trial once\n",
    "    directory='my_dir_2',  # Save results here\n",
    "    project_name='lstm_bayesian_tuning_2'\n",
    ")\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=2)\n",
    "\n",
    "# Get the best hyperparameterss\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"Best Hyperparameters: {best_hp.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.save('best_lstm_model_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters: {'lstm_units': 192, 'dropout_rate': 0.5, 'dense_units': 128, 'dropout_rate_2': 0.30000000000000004, 'learning_rate': 0.0010872353209015178}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import re\n",
    "\n",
    "# Step 1: Load the pre-trained model\n",
    "model = load_model('best_lstm_model.h5')\n",
    "\n",
    "# Step 2: Load the tokenizer used during training (you need to store it or recreate it)\n",
    "# Assuming you have the tokenizer stored, e.g., word_tokenizer\n",
    "# Load or create tokenizer (same as during training)\n",
    "word_tokenizer = Tokenizer()\n",
    "\n",
    "# If you have a saved tokenizer (saved as pickle, for example):\n",
    "# import pickle\n",
    "# with open('tokenizer.pickle', 'rb') as handle:\n",
    "#     word_tokenizer = pickle.load(handle)\n",
    "\n",
    "# Step 3: Define your text preprocessing function\n",
    "def preprocess_input_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess input text (tokenize and pad it).\n",
    "    \"\"\"\n",
    "    # Tokenize the text using the fitted tokenizer\n",
    "    tokenized_text = word_tokenizer.texts_to_sequences([text])\n",
    "\n",
    "    # Pad the sequence to ensure uniform input size (based on the training data)\n",
    "    maxlen = 100  # same as during training\n",
    "    padded_text = pad_sequences(tokenized_text, padding='post', maxlen=maxlen)\n",
    "    print(padded_text)\n",
    "    return padded_text\n",
    "\n",
    "# Step 4: Define the prediction function\n",
    "def predict_sentiment(text):\n",
    "    \"\"\"\n",
    "    Predict sentiment or class label for the input text.\n",
    "    \"\"\"\n",
    "    # Preprocess the input text\n",
    "    processed_text = preprocess_input_text(text)\n",
    "\n",
    "    # Get the prediction from the model\n",
    "    prediction = model.predict(processed_text)\n",
    "\n",
    "    # Assuming binary classification, return a label or probability\n",
    "    # If you have multiple classes, you can adjust the logic accordingly\n",
    "    if prediction >= 0.5:\n",
    "        return [prediction,\"Positive\"]  # or whatever label corresponds to class 1\n",
    "    else:\n",
    "        return [prediction,\"Negative\"]  # or whatever label corresponds to class 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Example usage\n",
    "input_text = \"Kill is an hello i am bad text for sentiment analysis.\"\n",
    "output = predict_sentiment(input_text)\n",
    "print(f\"Predicted Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_creds ={\n",
    "    \"apikey\": '_KnZKtXJvhFYIq2z5Ot08WKKpfBwbsgyj3CWsxYHJyds',\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_client = APIClient(wml_credentials=wml_creds)\n",
    "wml_client.spaces.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE_ID ='6760b3b6-140d-46c0-861e-2eebda2dd6ab'\n",
    "wml_client.set.default_space(SPACE_ID)\n",
    "print(f\"Default space is set to: {SPACE_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Python Version and Runtime for TensorFlow\n",
    "software_spec_uid = wml_client.software_specifications.get_id_by_name('tensorflow_rt23.1-py3.10')\n",
    "\n",
    "# # Setup model meta for custom TensorFlow model\n",
    "# model_props = {\n",
    "#     wml_client.repository.ModelMetaNames.NAME: 'FastBert Model', \n",
    "#     wml_client.repository.ModelMetaNames.TYPE: 'tensorflow_2.12',\n",
    "#     wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "# }\n",
    "model_dir = 'best_lstm_model.zip'\n",
    "\n",
    "# Define the location of requirements.txt\n",
    "requirements_file = 'requirement.txt'\n",
    "\n",
    "# Define the location of pipeline.py\n",
    "pipeline_file = 'lstm_pipeline.py'\n",
    "\n",
    "# Create the client to interact with WML\n",
    "\n",
    "# Upload the model\n",
    "model_metadata = {\n",
    "    wml_client.repository.ModelMetaNames.NAME: \"Best_82\",\n",
    "    wml_client.repository.ModelMetaNames.TYPE: \"tensorflow_2.12\",\n",
    "    wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n",
    "}\n",
    "\n",
    "# Store the model\n",
    "model_uid = wml_client.repository.store_model(model = model_dir, meta_props=model_metadata)\n",
    "\n",
    "# Print model UID\n",
    "print(f\"Model uploaded with UID: {model_uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_details = wml_client.repository.store_model(\n",
    "#     model='model_package',  # Path to the zip file\n",
    "#     meta_props=model_props\n",
    "# )\n",
    "# model_details\n",
    "\n",
    "model_uid = model_uid['metadata']['id']\n",
    "\n",
    "deployment_props = {\n",
    "    wml_client.deployments.ConfigurationMetaNames.NAME: 'FEMA-SentimentAnalysis',\n",
    "    wml_client.deployments.ConfigurationMetaNames.ONLINE: {\n",
    "        \"dependencies\": {\n",
    "            \"pip_requirements\": requirements_file,  # Point to the requirements file\n",
    "            \"python\": \"3.10\"  # Ensure the Python version is appropriate\n",
    "        },\n",
    "        \"pipeline\": pipeline_file  # Ensure the pipeline file is used for inference\n",
    "    }\n",
    "}\n",
    "\n",
    "# Deploy the model\n",
    "deployment = wml_client.deployments.create(\n",
    "    artifact_uid=model_uid,\n",
    "    meta_props=deployment_props\n",
    ")\n",
    "\n",
    "# Output result\n",
    "print(f\"Deployment created: {deployment}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"text\"],  # Name of the input field (this should match what the model expects)\n",
    "            \"values\": [[\"This is a sample text to analyze.\"]]  # List of texts you want to predict on\n",
    "        }\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# 1. Get the Deployment ID and Scoring URL from the deployment response\n",
    "deployment_uid = deployment['metadata']['id']\n",
    "deployment_url = deployment['entity']['status']['inference'][0]['url']  # Correct scoring URL\n",
    "\n",
    "# Set the version query parameter (you should use the correct version date)\n",
    "version = \"2021-06-28\"  # Replace this with the version of the Watson API you're using\n",
    "\n",
    "# 2. Prepare the input data (text)\n",
    "input_text = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"text\"],  # Input field name as expected by the model\n",
    "            \"values\": [[\"This is a test sentence for sentiment analysis.\"]]  # Example text for prediction\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 3. Prepare the headers for authentication and API version\n",
    "headers = {\n",
    "    \"Authorization\": \"_KnZKtXJvhFYIq2z5Ot08WKKpfBwbsgyj3CWsxYHJyds\",  # Replace with your IBM Cloud API key\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Add version to the scoring URL as a query parameter\n",
    "scoring_url_with_version = f\"{deployment_url}?version={version}\"\n",
    "\n",
    "# 4. Send the scoring request via the correct URL (use requests library instead)\n",
    "response = requests.post(scoring_url_with_version, headers=headers, data=json.dumps(input_text))\n",
    "\n",
    "# 5. Handle the response and print the prediction\n",
    "if response.status_code == 200:\n",
    "    prediction = response.json()\n",
    "    print(f\"Prediction: {prediction}\")\n",
    "else:\n",
    "    print(f\"Failed to get prediction. Status Code: {response.status_code}\")\n",
    "    print(f\"Response: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"embedding_input\"],  # Rename to match the model's expected field name for embeddings\n",
    "            \"values\": [X_test[0].tolist()]  # Convert numpy array to list if needed\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = wml_client.deployments.score(deployment_uid, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the payload to pass raw text if the pipeline handles embedding\n",
    "payload = {\n",
    "    \"input_data\": [\n",
    "        {\n",
    "            \"fields\": [\"text\"],  # Assuming the pipeline expects 'text' as input field\n",
    "            \"values\": [[\"This is a test sentence for sentiment analysis.\"]]  # Raw text\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Perform the inference\n",
    "result = wml_client.deployments.score(deployment_uid, payload)\n",
    "\n",
    "# Output the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Text-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
