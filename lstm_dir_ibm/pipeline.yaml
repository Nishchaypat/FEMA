version: '1.0'
name: 'Text Preprocessing and Inference Pipeline'

stages:
  - name: 'Text Preprocessing'
    type: 'python'
    script: |
      import numpy as np
      from tensorflow.keras.preprocessing.text import Tokenizer
      from tensorflow.keras.preprocessing.sequence import pad_sequences

      # Load the tokenizer and set the sequence length
      tokenizer = Tokenizer()  # Ensure this is fitted with the training data vocabulary
      max_sequence_length = 100  # Adjust to your model's input length

      # Define GloVe Embedding Load Function
      def load_glove_embeddings(glove_path='a2_glove.6B.100d.txt'):
          embeddings_index = {}
          with open(glove_path, 'r', encoding='utf8') as f:
              for line in f:
                  values = line.split()
                  word = values[0]
                  coeffs = np.asarray(values[1:], dtype='float32')
                  embeddings_index[word] = coeffs
          return embeddings_index

      # Create Embedding Matrix
      def create_embedding_matrix(tokenizer, embeddings_index, embedding_dim=100):
          word_index = tokenizer.word_index
          embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))
          for word, i in word_index.items():
              embedding_vector = embeddings_index.get(word)
              if embedding_vector is not None:
                  embedding_matrix[i] = embedding_vector
          return embedding_matrix

      # Define Preprocessing Pipeline Function
      def preprocess_text(text):
          # Tokenize and pad the input text to model's input length
          sequence = tokenizer.texts_to_sequences([text])
          padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)
          return padded_sequence

  - name: 'Model Inference'
    type: 'python'
    script: |
      import json
      from ibm_watson_machine_learning import APIClient
      import pipeline  # Import the pipeline module for preprocessing functions

      # Load Model from IBM Watson
      def load_model(model_uid):
          # IBM Watson Machine Learning credentials
          wml_credentials = {
              "apikey": "_KnZKtXJvhFYIq2z5Ot08WKKpfBwbsgyj3CWsxYHJyds",
              "url": "https://us-south.ml.cloud.ibm.com"
          }
          
          # Initialize the WML client
          client = APIClient(wml_credentials)
          
          # Retrieve the specific model's details using model_uid
          model_details = client.repository.get_model_details(model_uid)
          print("Model Details:", model_details)
          
          # Load the model
          model = client.repository.load(model_uid)
          return model

      # Define Prediction Function
      def predict(data, model_uid):
          # Load the model from IBM Watson Machine Learning
          model = load_model(model_uid)
          
          # Preprocess input text using the imported pipeline
          processed_data = pipeline.preprocess_text(data["text"])  # Preprocess before inference
          
          # Predict using the loaded model
          result = model.predict(processed_data)
          return json.dumps({"prediction": result.tolist()})
      
    inputs:
      - name: 'text_data'
        type: 'json'
        description: 'Text data for prediction'

    outputs:
      - name: 'prediction'
        type: 'json'
        description: 'Prediction result'
